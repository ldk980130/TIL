# FlatFileItemReader

## 파일 기반 배치 처리

- 파일 기반 데이터 처리는 실무에서 여전히 많이 쓰이고 중요한 역할을 한다.
    - ex) CSV, XML, JSON 등

### 파일 처리의 실체

- 파일 처리를 직접 구현한다면?
    - 파일을 열고 닫는 것부터가 힘들다.
    - 대용랑 파일의 경우 OutOfMemoryError가 나기 십상이다
    - try-catch로 점칠된 예외 처리에 스파게티 코드가 되기 쉽다.
    - 멀티스레드 환경이라면 데드락과 레이스 컨디션 확률이 높다.
    - 청크 일부만 쓰다 실패한다면 트랜잭션 롤백은 직접 해야 한다.

### 파일 기반 배치 처리

- 가장 기본적이면서 강력한 도구 두 가지는 다음과 같다.
    - `FlatFileItemReader`
    - `FlatFileItemWriter`

### Flat 파일이란

- CSV 같은 파일을 싱각하면 된다.
    - 단순히 열과 행으로만 구성된 파일
- 플랫 파일의 특징
    - 각 라인이 하나의 데이터 (레코드 개념)
    - 다양한 구분자 지원
        - CSV의 경우 쉼표로 각 필드를 구분한다.
        - TSV의 경우 탭(\t)으로 구분한다.
    - 강력한 호환성과 범용성
        - 거의 모든 시스템에서 읽고 쓸 수 있는 표준이다.

## FlatFileItemReader

- 플랫 파일로부터 데이터를 읽어오는 Spring Batch의 핵심 도구 중 하나
- `read()` 메서드 동작은 크게 두 단계로 이루어진다.
    - 파일에서 한 줄을을 읽기
    - 읽어온 한 줄을 객체로 변환해 리턴

```java
// FlatFileItemReader.doRead()
// ...
String line = readLine();
// ...
return lineMapper.mapLine(line, lineCount); 
```

- 객체 변환 과정에선 `LineMapper`라는 컴포넌트가 핵심을 담당한다.
    - Spring JDBC의 `RowMapper`와 유사

```java
public interface LineMapper<T> {
    T mapLine(String line, int lineNumber) throws Exception;
}
```

## DefaultLineMapper

- Spring Batch는 이미 강력한 기본 구현체인 `DefaultLineMapper`를 제공한다.
- `DefaultLineMapper` 동작도 크게 두 단계로 이루어진다.
  - 토근화(Tokenization)
    - 하나의 문자열 라인을 토큰 단위로 분리
    - 구분자를 기준으로 각 컬럼을 분리한다.
  - 객체 매핑
    - 분리된 토큰들을 객체 프로퍼티에 매핑

```java
@Override
public T mapLine(String line, int lineNumber) throws Exception {
    FieldSet fieldSet = tokenizer.tokenize(line);  // 1단계: 토큰화
    return fieldSetMapper.mapFieldSet(fieldSet);  // 2단계: 객체 매핑	 
}
```

### 1단계: 토큰화 - `LineTokenizer`

- 토큰화 단계에선 `LineTokenizer` 컴포넌트가 사용된다.
- `LineTokenizer` 구현체는 대표적으로 다음 두 가지가 있다.
  - `DelimitedLineTokenizer` - 쉼표(`,`) 구분자로 데이터를 토큰화
    - ex) `ERR001,2024-01-19,CRITICAL` -> `["ERR001", "2024-01-19", "CRITICAL"]`
  - `FixedLengthTokenizer` - 고정된 길이로 구분된 데이터를 토큰화
    - `ERR00120240119CRITICAL` -> `["ERR001", "20240119", "CRITICAL"]` (각 6, 8, 8자리)
  - 어떤 구현체를 사용할지 `FlatFileItemReader` 구성 시점에 선택 가능하다.
- 데이터를 토큰화한 결과를 `FieldSet` 객체로 만들어 변환한다.

```java
public class DefaultFieldSet implements FieldSet {
   private final String[] tokens; // 토큰화된 데이터
   private List<String> names; // 각 데이터를 객체의 어떤 프로퍼티에 매핑할지 나타내는 프로퍼티 이름 목록
   // ...
}
```

- ex) `"ERR001,2024-01-19 10:15:23,CRITICAL,1234,SYSTEM_CRASH”`
  - `tokens`: `["ERR001", "2024-01-19 10:15:23", "CRITICAL", "1234", "SYSTEM_CRASH"]`
  - `names`: `["errorId", "errorDateTime", "severity", "processId", "errorMessage"]`
