# 11장 스트림 처리
- ‘스트림’은 일반적으로 시간 흐름에 따라 점진적으로 생산된 데이터를 일컫는다.
- 일괄 처리와 달리 스트림은 데이터가 점진적으로 처리된다.

## 이벤트 스트림 전송

- 스트림 처리에서 입력은 보통 ‘이벤트’라고 한다.
    - 특정 시점에 일어난 사건의 세부 사항
    - 작고 독립된 불변 객체
    - 이벤트 발생 타임스탬프를 포함
    - 텍스트 문자열이나 JSON 또는 이진 형태 등으로 부호화된다.
- 이벤트 스트리밍에서도 한 번 기록한 이벤트를 여러 곳에서 읽을 수 있다.
    - 생산자(producer)가 이벤트를 한 번 생성하면 여러 소비자(consumer)가 처리할 수 있다.
    - 스트림 시스템에선 대개 토픽(topic)이나 스트림으로 관련 이벤트를 묶는다.
- 전통적 데이터베이스는 알림 메커니즘을 강력히 지원하지 않는다.
    - 이론상으론 폴링을 사용하여 데이터베이스만 있다면 스트림 처리를 구현할 수 있지만 풀링은 비용이 크다.
    - 트리거(trigger) 기능이 있긴 하지만 제한적이다.

### 메시징 시스템

- 메시징 시스템은 새로운 이벤트에 대해 소비자에게 알려주려고 쓰이는 방법이다.
    - 다수의 생산자 노드가 같은 토픽으로 메시지 전송 가능
    - 다수의 소비자 노드가 토픽 하나에서 메시지를 소비 가능
    - 메시징 시스템에선 발행/구독(publish/subscribe) 모델을 사용한다.
- 많은 메시지 시스템은 중간 노드 없이 생산자와 소비자가 네트워크로 직접 통신한다.
    - 낮은 지연이 필수인 주식 시장과 금융 산업에서 널리 사용된다. (UDP 멀티캐스트)
    - ZeroMQ 같은 브로커가 필요 없는 메시징 라이브러리도 이 방식을 사용
    - 메시지가 유실될 수도 있기에 애플리케이션 코드로 이를 보완해야하지만 상당히 제한적이다.
- 메시지 브로커(메시지 큐)
    - 메시지 스트림 처리에 최적화된 데이터베이스의 일종이다.
    - 생산자는 브로커로 메시지를 전송하고 소비자는 브로커에서 메시지를 읽는다.
    - 브로커에 데이터가 모이기에 클라이언트(생산자/소비자)의 장애에 쉽게 대처 가능하다.
        - 메시지를 메모리에만 보관할 수도 있지만 디스크에 메시지를 기록하는 브로커도 있다.
        - 소비 속도가 느린 소비자가 있다면 일반적으로 큐가 제한 없이 계속 늘어난다.
    - 소비자는 일반적으로 비동기로 동작한다.
- 메시지 브로커와 데이터베이스의 비교
    - 데이터베이스와 달리 브로커 대부분은 소비자에게 배달 성공 후 자동으로 메시지를 삭제한다.
    - 브로커 대부분은 메시지를 빨리 지우기에 큐 크기가 작다.
    - 데이터베이스는 다양한 데이터 검색을 지원하는 반면 메시지 브로커는 특정 패턴과 부합하는 토픽의 부분 집합을 구독하는 방식을 지원한다.
    - 메시지 브로커는 데이터베이스의 스냅샷 기반의 임의 질의를 하지는 않지만 데이터가 변하면 클라이언트에게 즉시 알려준다.
- 복수 소비자가 같은 토픽에서 메시지를 읽을 때 사용하는 주요 패턴 두 가지가 있다.
    - 로드 밸런싱 - 소비자 중 하나로 전달
    - 팬 아웃 - 모든 소비자에게 전달
- 확인 응답과 재전송
    - 메시지 유실을 막기 위해 메시지 브로커는 확인 응답을 사용한다.
        - 클라이언트는 메시지 처리가 끝나고 브로커가 큐에서 메시지를 제거할 수 있게 브로커에게 명시적으로 알림
    - 브로커가 확인 응답을 받지 않으면 메시지가 처리되지 않았다고 가정하고 다른 소비자에게 다시 전송한다.
    - 메시지 재전송으로 인해 메시지 순서가 순서대로 처리되지 않을 수도 있다.
    - 소비자마다 독립된 큐를 사용하면 순서가 꼬이는 문제를 피할 수는 있다.
### 파티셔닝된 로그

- 일반적인 데이터베이스와 메시징 시스템은 데이터에 대한 접근법이 다르다.
  - 데이터베이스나 파일 시스템은 기본적으로 모든 데이터를 명시적 삭제 이전까진 영구 보존한다.
  - 메시징 시스템은 소비자에게 메시지를 전달 후 즉시 삭제하기에 한 번 지나간 메시지는 복구할 수 없다.
- 로그 기반 메시지 브로커(log-based message broker)
  - 데이터베이스의 지속성과 메시징 시스템의 지연이 짧은 알림 기능을 조합한 것
  - 생산자가 보낸 메시지를 로그 끝에 추가하고 소비자는 순차적으로 메시지를 받는다.
  - ex) 아파치 카프카(Apache Kafka), 아마존 키네시스 스트림(Amazon Kinesis Stream) 등
- 로그 기반 메시징 시스템은 처리량을 높이기 위해 로그를 파티셔닝한다.
  - 각 파티션은 다른 파티션과 독립적으로 읽고 쓰이는 분리된 로그가 된다.
  - 토픽은 같은 형식의 메시지를 전달하는 파티션들의 그룹으로 정의한다.
  - 각 파티션에는 모든 메시지에 오프셋이라는 단조 증가하는 순번을 부여하여 순서를 보장한다.
- 로그 방식과 전통적 메시징 방식의 비교
  - 로그 기반 접근법
    - 팬 아웃 방식을 제공해 각 소비자가 독립적으로 로그를 읽을 수 있게 할 수 있다.
    - 메시지를 읽어도 로그에서 삭제되지 않는다.
    - 소비자 그룹의 노드들에게 전체 파티션을 할당해 로드 밸런싱을 수행할 수 있다.
    - 메시지 처리 속도가 빠르고 메시지 순서가 중요한 경우 효과적이다.
    - 단 메시지 처리 비용이 상대적으로 높을 수 있다.
  - 전통적 메시징 방식
    - 메시지 순서가 중요하지 않은 경우 적합할 수 있다.
    - 메시지 처리 속도가 상대적으로 느릴 수 있다.
- 로그를 계속 추가하다보면 결국 디스크 공간에 부담이 간다.
  - 디스크 공간 재사용을 위해 로그를 여러 조각으로 나누고 가끔 오래된 조각을 삭제하거나 이동시킨다.
  - 소비자 처리 속도가 너무 느린 경우 소비자 오프셋이 이미 삭제한 로그 조각을 가리킬 수 있어 메시지가 유실될 수 있다.
  - 그래도 로그는 일반적으로 하드디스크 버퍼에 수 일에서 수주간 메시지를 보관할 수 있다.
- 로그 기반 메시징 시스템은 소비자가 생산자를 따라갈 수 없을 때 대용량 고정 크기의 버퍼링을 통해 대응한다.
  - 로그는 크기가 제한된 버퍼로 구현하고 버퍼가 가득 차면 오래된 메시지 순서대로 버린다. (링 버퍼, 원형 버퍼)
  - 어떤 소비자가 너무 뒤쳐져 메시지를 잃기 시작해도 해당 소비자만 영향 받고 다른 소비자들 서비스는 영향 받지 않는다.
- 확인 응답을 받아야했던 전통적 메시징 시스템과 달리 로그 기반 방식은 읽기 전용 연산으로 메시지를 읽는다.
  - 메시지 처리의 유일한 부수 효과는 소비자 오프셋 이동이지만 오프셋 관리는 소비자 관리 아래 있어 관리가 용이하다.

## 데이터베이스와 스트림

### 시스템 동기화 유지하기

- 대부분 애플리케이션은 요구사항 만족을 위해  여러 기술의 조합이 필요한데 여러 데이터 저장소의 동기화는 필수다.
  - ex) 데이터베이스를 갱신하면 캐시와 색인과 데이터 웨어하우스도 갱신해야 함
- 이중 기록(dual write)
  - 데이터가 변할 때마다 애플리케이션 코드에서 명식적으로 각 시스템에 기록
  - 이중 기록은 몇 가지 문제가 존재한다.
    - 동시 쓰기 문제가 발생
    - 내결함성 문제로 시스템 간 불일치가 발생할 수 있음
    - 원자적 커밋 문제

### 변경 데이터 캡쳐

- 변경 데이터 캡쳐 (change data capture, CDC)
  - 데이터베이스 기록의 모든 변화를 관찰해 다른 시스템으로 복제할 수 있는 형태로 추출하는 과정이다.
  - 데이터베이스 변경사항을 실시간 스트림으로 제공
- CDC의 구현
  - 캡쳐할 데이터베이스 하나를 리더로, 나머지를 팔로워로 지정
  - 로그 기반 메시지 브로커는 원본 데이터베이스에서 변경 이벤트를 전송하기에 적합하다. (순서를 유지하기 때문)
  - 데이터베이스 트리거를 사용할 수도 있지만 고장 나기 쉽고 성능 오버헤드가 상당하다.
  - CDC는 비동기 방색으로 동작하기에 데이터베이스 변경 사항을 커미샇기 전에 소비자에게 적용될 때까지 기다리지 않는다.
- 일부 CDC 도구는 스냅숏 기능을 내장하고 있으나 수작업으로 진행해야 하는 CDC 도구도 있다.
  - 데이터베이스의 모든 변경 로그를 통해 로그를 재현해 데이터베이스 전체 상태를 재구축할 수 있다.
  - 대부분의 변경 사항을 영구적으로 보관할 순 없기에 일관성 있는 스냅숏이 필요하다.
  - 데이터베이스 스냅숏은 변경 로그의 위치나 오프셋에 대응되어야 스냅숏 이후 변경에 대응할 수 있다.
- 로그 컴팩션
  - 새로운 파생 데이터 시스템을 추가할 때마다 스냅숏을 만들어야 하는 번거로움을 해결하기 위한 대안
  - 주기적으로 같은 키의 로그 레코드를 찾아 중복을 제거해 가장 최근 갱신 내용만 유지
  - 컴팩션과 병합 과정은 백그라운드로 실행된다.
  - CDC 시스템에서도 모든 변경에 기본키가 포함되게 하고 키의 모든 갱신이 해당 키의 이전 값을 교체한다면 특정 키에 대해 최신 쓰기만 유지하면 충분하다.
  - 즉 CDC 원본 데이터베이스의 스냅숏 없이도 전체 복사본을 얻을 수 있다.
  - 아파치 카프카는 로그 컴팩션 기능을 제공한다.
- 변경 스트림용 API 지원
  - 리싱크DB(RethinkDB) - 질의 결과에 변경이 있을 때 알림을 받도록 구독이 가능한 질의를 지원
  - 파이어베이스와 카우치 DB(CouchDB) - 애플리케이션에도 사용 가능한 변경 피드 기반 데이터 동기화를 지원
  - 미티어(Meteor) - 몽고DB의 oplog를 사용해 데이터 변경사항을 구독하거나 사용자 인터페이스를 갱신
  - 카프카 커넥트(Kafka Connect)
    - 카프카를 광범위한 데이터 시스템용 변경 데이터 캡쳐 도구로 활용 가능
    - 파생 데이터 시스템 갱신에 사용 가능하다.
    - 스트림 처리 시스템에도 이벤트 공급이 가능
